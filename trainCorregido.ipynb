{
 "metadata": {
  "name": "trainCorregido"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load train.py"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import time\n",
      "from pytz import timezone\n",
      "from datetime import datetime\n",
      "from sklearn.metrics import roc_auc_score, make_scorer\n",
      "from multiprocessing import cpu_count\n",
      "from time import strftime, gmtime\n",
      "from sklearn.feature_extraction.text import CountVectorizer\n",
      "#from sklearn.feature_extraction.text import TfidfVectorizer\n",
      "#from sklearn.cross_validation import train_test_split\n",
      "from sklearn.grid_search import GridSearchCV\n",
      "#from sklearn.cross_validation import cross_val_score\n",
      "#from sklearn.svm import LinearSVC\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "#from sklearn.pipeline import Pipeline\n",
      "from scipy import sparse\n",
      "#from sklearn.ensemble import RandomForestClassifier\n",
      "from IPython.core.debugger import Tracer\n",
      "\n",
      "\n",
      "def load_data():\n",
      "    print(\"loading\")\n",
      "    comments = []\n",
      "    dates = []\n",
      "    labels = []\n",
      "\n",
      "    with open(\"train.csv\") as f:\n",
      "        f.readline()\n",
      "        for line in f:\n",
      "            splitstring = line.split(',')\n",
      "            labels.append(splitstring[0])\n",
      "            dates.append(splitstring[1][:-1])\n",
      "            comment = \",\".join(splitstring[2:])\n",
      "            comment = comment.strip().strip('\"')\n",
      "            comment.replace('_', ' ')\n",
      "            comments.append(comment)\n",
      "    labels = np.array(labels, dtype=np.int)\n",
      "    dates = np.array(dates)\n",
      "    return comments, dates, labels\n",
      "\n",
      "\n",
      "def load_test():\n",
      "    print(\"loading test set\")\n",
      "    comments = []\n",
      "    dates = []\n",
      "\n",
      "    with open(\"test.csv\") as f:\n",
      "        f.readline()\n",
      "        for line in f:\n",
      "            splitstring = line.split(',')\n",
      "            dates.append(splitstring[0][:-1])\n",
      "            comment = \",\".join(splitstring[1:])\n",
      "            comment = comment.strip().strip('\"')\n",
      "            comment.replace('_', ' ')\n",
      "            comments.append(comment)\n",
      "    dates = np.array(dates)\n",
      "    return comments, dates\n",
      "\n",
      "\n",
      "def write_test(labels, fname=\"test_prediction.csv\"):\n",
      "    with open(\"test.csv\") as f:\n",
      "        with open(fname, 'w') as fw:\n",
      "            fw.write(f.readline())\n",
      "            for label, line in zip(labels, f):\n",
      "                fw.write(\"%f,\" % label)\n",
      "                fw.write(line)\n",
      "\n",
      "\n",
      "def grid_search():\n",
      "    tracer = Tracer()\n",
      "    \n",
      "    comments, dates, labels = load_data()\n",
      "    # get the google bad word list\n",
      "    with open(\"google_badlist.txt\") as f:\n",
      "        badwords = [l.strip() for l in f.readlines()]\n",
      "        badword_doc = \" \".join(badwords)\n",
      "    \n",
      "    comments.append(badword_doc)\n",
      "    \n",
      "    #countvect = CountVectorizer(max_n=2, analyzer=\"char\")\n",
      "    countvect = CountVectorizer(ngram_range=(1,2))\n",
      "    counts = countvect.fit_transform(comments).tocsr()\n",
      "    badword_counts = counts[-1, :]\n",
      "    counts = counts[:-1, :]\n",
      "    comments.pop(-1)\n",
      "    \n",
      "    ## some handcrafted features!\n",
      "    n_words = [len(c.split()) for c in comments]\n",
      "    n_chars = [len(c) for c in comments]\n",
      "    # number of uppercase words\n",
      "    allcaps = [np.sum([w.isupper() for w in comment.split()])\n",
      "           for comment in comments]\n",
      "    # longest word\n",
      "    max_word_len = [np.max([len(w) for w in c.split()]) for c in comments]\n",
      "    # average word length\n",
      "    mean_word_len = [np.mean([len(w) for w in c.split()]) for c in comments]\n",
      "    # number of google badwords:\n",
      "    n_bad = counts * badword_counts.T\n",
      "    \n",
      "    features = np.array([n_words, n_chars, allcaps, max_word_len,\n",
      "        mean_word_len, n_bad.toarray()]).T\n",
      "    \n",
      "    features = sparse.hstack([counts, features])\n",
      "    \n",
      "    ## exlamation marks\n",
      "    #excl = [comment.count(\"!\") for comment in comments]\n",
      "    ## double exlamation marks\n",
      "    #excl2 = [comment.count(\"!!\") for comment in comments]\n",
      "    \n",
      "    #countvect = TfidfVectorizer()\n",
      "    \n",
      "    print(\"vectorizing\")\n",
      "    #counts_array = counts.toarray()\n",
      "    #indicators = sparse.csr_matrix((counts_array > 0).astype(np.int))\n",
      "    \n",
      "    #X_train, X_test, y_train, y_test = train_test_split(counts, labels,\n",
      "                                                        #test_size=0.5)\n",
      "    #inds = np.random.permutation(len(labels))\n",
      "    #n_samples = len(labels)\n",
      "    #print(\"training\")\n",
      "    param_grid = dict(C=2. ** np.arange(-6, 4),\n",
      "            penalty=['l1', 'l2'])\n",
      "            #vect__max_n=np.arange(1, 4), vect__lowercase=[True, False])\n",
      "    #clf = LinearSVC(tol=1e-8, penalty='l1', dual=False, C=0.5)\n",
      "    clf = LogisticRegression(tol=1e-8)\n",
      "    #pipeline = Pipeline([('vect', countvect), ('logr', clf)])\n",
      "    \n",
      "    #clf = NearestCentroid()\n",
      "    \n",
      "    #param_grid = dict(max_depth=np.arange(1, 10))\n",
      "    #clf = RandomForestClassifier(n_estimators=10)\n",
      "    \n",
      "    puntuador = make_scorer(roc_auc_score, greater_is_better = True)\n",
      "    numerocpus = cpu_count()\n",
      "    grid = GridSearchCV(clf, cv=2, param_grid=param_grid, verbose=4, scoring=puntuador,\n",
      "            n_jobs=numerocpus)\n",
      "    #print(cross_val_score(clf, counts, labels, cv=3))\n",
      "    \n",
      "    #grid.fit(counts, labels)\n",
      "    grid.fit(features, labels)\n",
      "    #clf.fit(X_train, y_train)\n",
      "    #print(clf.score(X_test, y_test))\n",
      "    #tracer()\n",
      "    \n",
      "    comments_test, dates_test = load_test()\n",
      "    comments_test.append(badword_doc)\n",
      "    counts_test = countvect.transform(comments_test).tocsr()\n",
      "    \n",
      "    badword_counts = counts_test[-1, :]\n",
      "    counts_test = counts_test[:-1, :]\n",
      "    comments_test.pop(-1)\n",
      "    \n",
      "    ## some handcrafted features!\n",
      "    n_words = [len(c.split()) for c in comments_test]\n",
      "    n_chars = [len(c) for c in comments_test]\n",
      "    # number of uppercase words\n",
      "    allcaps = [np.sum([w.isupper() for w in comment.split()])\n",
      "           for comment in comments_test]\n",
      "    # longest word\n",
      "    max_word_len = [np.max([len(w) for w in c.split()]) for c in comments_test]\n",
      "    # average word length\n",
      "    mean_word_len = [np.mean([len(w) for w in c.split()]) for c in comments_test]\n",
      "    # number of google badwords:\n",
      "    n_bad = counts_test * badword_counts.T\n",
      "    \n",
      "    features_test = np.array([n_words, n_chars, allcaps, max_word_len,\n",
      "        mean_word_len, n_bad.toarray()]).T\n",
      "    \n",
      "    features_test = sparse.hstack([counts_test, features_test])\n",
      "    \n",
      "    \n",
      "    prob_pred = grid.best_estimator_.predict_proba(features_test)\n",
      "    print(prob_pred)\n",
      "    write_test(prob_pred[:, 1])\n",
      "    return grid, \n",
      "    \n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    inicio = time.time()\n",
      "    grid_search()\n",
      "    final = time.time()\n",
      "    tiempoTotal = final - inicio\n",
      "    \n",
      "    tiempoMexico = timezone('America/Mexico_City')\n",
      "    \n",
      "    \n",
      "    print(\"El tiempo de ejecucion transcurrido fue de: \" + str(tiempoTotal) + \" segundos.\")\n",
      "    with open(\"resultados.txt\",'w') as archivo:\n",
      "        archivo.write(\"*** \" + str(datetime.now(tiempoMexico)) + \"\\n\\n\")\n",
      "        archivo.write(\"\\tEl tiempo de ejecucion transcurrido fue de: \" + str(tiempoTotal) + \" segundos.\\n\")\n",
      "        archivo.write (\"\\tEl modelo utilizado fue:\\n\\t\\t\" + str(grid.best_estimator_) )\n",
      "        archivo.write(\"\\n\\tEl cual tuvo una AUC de: \" + str(grid.best_score_))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "loading\n",
        "vectorizing"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Fitting 2 folds for each of 20 candidates, totalling 40 fits\n"
       ]
      }
     ],
     "prompt_number": "*"
    }
   ],
   "metadata": {}
  }
 ]
}